{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Fw4Xe7xRwcrW",
   "metadata": {
    "id": "Fw4Xe7xRwcrW"
   },
   "source": [
    "**案例教学3-Agents SDK+Qianwen+MCP智能体开发实战**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K6kM1uPoOtPe",
   "metadata": {
    "id": "K6kM1uPoOtPe"
   },
   "source": [
    "1. Agent SDK知识回顾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AO-lIKWGznqx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15467,
     "status": "ok",
     "timestamp": 1755912748352,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "AO-lIKWGznqx",
    "outputId": "44c439ee-70f0-4dd6-c5b2-146941cece4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==1.99.9\n",
      "  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.99.9) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.99.9) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.99.9) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.99.9) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.99.9) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai==1.99.9) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai==1.99.9) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai==1.99.9) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai==1.99.9) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==1.99.9) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==1.99.9) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.99.9) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.99.9) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.99.9) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.99.9) (0.4.1)\n",
      "Downloading openai-1.99.9-py3-none-any.whl (786 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.100.0\n",
      "    Uninstalling openai-1.100.0:\n",
      "      Successfully uninstalled openai-1.100.0\n",
      "Successfully installed openai-1.99.9\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==1.99.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26750119-5eb1-4a75-a56b-a27df5088805",
   "metadata": {
    "id": "26750119-5eb1-4a75-a56b-a27df5088805"
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7c792-b17f-4a17-8dfb-e277aa84a118",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1755913007716,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "38b7c792-b17f-4a17-8dfb-e277aa84a118",
    "outputId": "4bff613d-c23c-44b3-c292-15bb8fc03fb4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1.99.9'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6Aiz8xRFxFdi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4449,
     "status": "ok",
     "timestamp": 1755913014362,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "6Aiz8xRFxFdi",
    "outputId": "44365714-b6e4-4263-ee67-215998aba58a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VQ6WWikxyRbq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6147,
     "status": "ok",
     "timestamp": 1755913022536,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "VQ6WWikxyRbq",
    "outputId": "2daf32c8-16fb-47b4-f1e7-0a518c109032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-agents\n",
      "  Downloading openai_agents-0.2.9-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
      "  Downloading griffe-1.12.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: mcp<2,>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (1.13.0)\n",
      "Requirement already satisfied: openai<2,>=1.99.6 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (1.99.9)\n",
      "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.32.4)\n",
      "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
      "  Downloading types_requests-2.32.4.20250809-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (4.14.1)\n",
      "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.10.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.4.1)\n",
      "Requirement already satisfied: httpx>=0.27.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.47.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.35.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.99.6->openai-agents) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.99.6->openai-agents) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.99.6->openai-agents) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.99.6->openai-agents) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.27.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents) (1.1.1)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents) (8.2.1)\n",
      "Downloading openai_agents-0.2.9-py3-none-any.whl (175 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading griffe-1.12.1-py3-none-any.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_requests-2.32.4.20250809-py3-none-any.whl (20 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: types-requests, colorama, griffe, openai-agents\n",
      "Successfully installed colorama-0.4.6 griffe-1.12.1 openai-agents-0.2.9 types-requests-2.32.4.20250809\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd288c3c-63a3-47fd-8161-bf2691a8aba3",
   "metadata": {
    "id": "cd288c3c-63a3-47fd-8161-bf2691a8aba3"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "from openai import AsyncOpenAI\n",
    "from agents import OpenAIChatCompletionsModel,Agent,Runner,set_default_openai_client\n",
    "from agents.model_settings import ModelSettings\n",
    "from contextlib import AsyncExitStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18KdaFBCyyuL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5287,
     "status": "ok",
     "timestamp": 1755913044484,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "18KdaFBCyyuL",
    "outputId": "508ce47a-aa48-4303-84aa-cc2e7312f36f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n"
     ]
    }
   ],
   "source": [
    "%pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e5f0f-a3a2-432d-9631-a248c27031be",
   "metadata": {
    "id": "839e5f0f-a3a2-432d-9631-a248c27031be"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from agents import OpenAIChatCompletionsModel,Agent,Runner,set_default_openai_client\n",
    "from agents.model_settings import ModelSettings\n",
    "from agents import function_tool\n",
    "import requests,json\n",
    "import pymysql\n",
    "\n",
    "from agents import (\n",
    "    Agent,\n",
    "    HandoffOutputItem,\n",
    "    ItemHelpers,\n",
    "    MessageOutputItem,\n",
    "    RunContextWrapper,\n",
    "    Runner,\n",
    "    ToolCallItem,\n",
    "    ToolCallOutputItem,\n",
    "    TResponseInputItem,\n",
    "    function_tool,\n",
    "    handoff,\n",
    "    trace,\n",
    ")\n",
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "\n",
    "from IPython.display import display, Code, Markdown, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490e890-4ed1-46e9-aae3-9899efbaa0c7",
   "metadata": {
    "id": "7490e890-4ed1-46e9-aae3-9899efbaa0c7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "import json\n",
    "import io\n",
    "import inspect\n",
    "import requests\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import base64\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import dateutil.parser as parser\n",
    "import tiktoken\n",
    "from lxml import etree\n",
    "\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Code, Markdown, Image\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077203ed-6545-4e90-9eb3-ec35d8f8a048",
   "metadata": {
    "id": "077203ed-6545-4e90-9eb3-ec35d8f8a048"
   },
   "source": [
    "- Qianwen API调用流程回顾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498088f4-d952-4609-8c17-ea583acd52e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3410,
     "status": "ok",
     "timestamp": 1755913194327,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "498088f4-d952-4609-8c17-ea583acd52e2",
    "outputId": "a28ea5f3-a284-4855-8240-78b3d099e299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好！我是Qwen，是阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我可以帮助您完成很多任务，比如：\n",
      "\n",
      "- 回答各种问题，包括学术、文化、技术等领域的问题\n",
      "- 创作文字，如撰写故事、公文、邮件、剧本等\n",
      "- 进行逻辑推理和编程\n",
      "- 表达观点，参与讨论\n",
      "- 玩一些文字游戏\n",
      "\n",
      "如果您有任何问题或需要帮助，欢迎随时告诉我！\n"
     ]
    }
   ],
   "source": [
    "# 读取模型API-KEY\n",
    "api_key = os.getenv(\"ALIBABA_API_KEY\", \"sk-XXXXX(自己的API-KEY)\")\n",
    "\n",
    "# 实例化客户端\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "# 调用 qianwen 模型\n",
    "response = client.chat.completions.create(\n",
    "\n",
    " model=\"qwen-plus\",\n",
    " messages=[\n",
    "     {\"role\": \"system\", \"content\": \"You are a helpful coding assistant. Please complete the code implementation.\"},\n",
    "     {\"role\": \"user\", \"content\": \"您好，请介绍一下你自己\"},\n",
    " ],\n",
    " max_tokens=500,\n",
    ")\n",
    "\n",
    "# 输出生成的响应内容\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b27b9-ce8f-4d98-9e1f-9c688e8e5555",
   "metadata": {
    "id": "c14b27b9-ce8f-4d98-9e1f-9c688e8e5555"
   },
   "source": [
    "- Agents SDK基本调用流程回顾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f07038-eb24-4c7e-8dc6-b1bdfb1c55c9",
   "metadata": {
    "id": "f4f07038-eb24-4c7e-8dc6-b1bdfb1c55c9"
   },
   "outputs": [],
   "source": [
    "external_client = AsyncOpenAI(\n",
    "    base_url = \"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "set_default_openai_client(external_client)\n",
    "\n",
    "qianwen_model = OpenAIChatCompletionsModel(\n",
    "    model=\"qwen-plus\",\n",
    "    openai_client=external_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ba2e4-c626-42eb-890a-8da498d420a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1457,
     "status": "ok",
     "timestamp": 1755913207116,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "065ba2e4-c626-42eb-890a-8da498d420a5",
    "outputId": "d78780c7-d8aa-4049-9f2c-81356581a70e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "函数唤自身，  \n",
      "代码深处无限环，  \n",
      "递归入梦间。\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(name=\"Assistant\",\n",
    "              instructions=\"你是一名助人为乐的助手。\",\n",
    "              model=qianwen_model)\n",
    "\n",
    "result = await Runner.run(agent, \"请写一首关于编程中递归的俳句。\")\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd23d9a1-4ebe-46f6-bf9c-6360869f40b5",
   "metadata": {
    "id": "fd23d9a1-4ebe-46f6-bf9c-6360869f40b5"
   },
   "source": [
    "现在，我们仅需在创建Agent的时候，将MCP服务器视作为一项工具，即可顺利调用MCP服务器进行Agent开发。而实际在借助Agents SDK调用MCP的流程也非常简单，我们`只需将MCP视作tools`，即可进行调用。换而言之，就是如果使用Agents SDK作为Agent开发框架，则可以零门槛快速接入MCP海量服务器生态。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0a26ea-b3c8-4516-a85e-5ab48c4ea82a",
   "metadata": {
    "id": "dd0a26ea-b3c8-4516-a85e-5ab48c4ea82a"
   },
   "source": [
    "### 2.MCP技术回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f99f2-fb53-4e69-8838-ec1c1da10b9f",
   "metadata": {
    "id": "8f9f99f2-fb53-4e69-8838-ec1c1da10b9f"
   },
   "source": [
    "&emsp;&emsp;MCP，全称是Model Context Protocol，模型上下文协议，由Claude母公司Anthropic于去年11月正式提出。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7fe291-c07c-45ff-895b-6e0566445fb2",
   "metadata": {
    "id": "dc7fe291-c07c-45ff-895b-6e0566445fb2"
   },
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250318201338022.png\" alt=\"image-20250318201338022\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29745869-8ae2-46f9-a177-8b0d1d573aad",
   "metadata": {
    "id": "29745869-8ae2-46f9-a177-8b0d1d573aad"
   },
   "source": [
    "> - Anthropic MCP发布通告：https://www.anthropic.com/news/model-context-protocol\n",
    "> - MCP GitHub主页：https://github.com/modelcontextprotocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6ccf8-0611-48f5-937b-25dbe0eaca57",
   "metadata": {
    "id": "e5b6ccf8-0611-48f5-937b-25dbe0eaca57"
   },
   "source": [
    "MCP的核心作用，是统一了Agent开发过程中，大模型调用外部工具的技术实现流程，从而大幅提高Agent开发效率。在MCP诞生之前，不同的外部工具各有不同的调用方法，要连接这些外部工具开发Agent，就必须“每一把锁单独配一把钥匙”，开发工作非常繁琐："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de48e93-1993-4339-be43-fb8462d15960",
   "metadata": {
    "id": "1de48e93-1993-4339-be43-fb8462d15960"
   },
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250403170211085.png\" alt=\"image-20250403170211085\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6acbb61-749a-4599-a91e-ecffeea9817a",
   "metadata": {
    "id": "b6acbb61-749a-4599-a91e-ecffeea9817a"
   },
   "source": [
    "而MCP的诞生，则统一了这些外部工具的调用流程，使得无论什么样的工具，都可以借助MCP技术按照统一的一个流程快速接入到大模型中，从而大幅加快Agent开发效率。这就好比现在很多设备都可以使用type-c和电脑连接类似。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2bc42c-9d31-444b-92e1-7a269c319b1b",
   "metadata": {
    "id": "4f2bc42c-9d31-444b-92e1-7a269c319b1b"
   },
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250403170238895.png\" alt=\"image-20250403170238895\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5913c9-516c-4e6f-a753-9379b19db9ba",
   "metadata": {
    "id": "fe5913c9-516c-4e6f-a753-9379b19db9ba"
   },
   "source": [
    "从技术实现角度来看，我们可以将MCP看成是Function calling的一种封装，通过server-client架构和一整套开发工具，来规范化Function calling开发流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff5d62e-76bb-49fb-bcbc-97d161d7b91d",
   "metadata": {
    "id": "fff5d62e-76bb-49fb-bcbc-97d161d7b91d"
   },
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250318202116026.png\" alt=\"image-20250318202116026\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a688fb28-fcb9-4ba6-bb79-5c3793edd3bb",
   "metadata": {
    "id": "a688fb28-fcb9-4ba6-bb79-5c3793edd3bb"
   },
   "source": [
    "换而言之，Agents SDK实现MCP技术流程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c65ec-f5d6-4a6d-85b5-2a982e116c8e",
   "metadata": {
    "id": "724c65ec-f5d6-4a6d-85b5-2a982e116c8e"
   },
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250403171429137.png\" alt=\"image-20250403171429137\" style=\"zoom:50%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced9589-c8b7-4e71-8b19-338b639381e0",
   "metadata": {
    "id": "eced9589-c8b7-4e71-8b19-338b639381e0"
   },
   "source": [
    "除此之外，实际上，MCP提供了三个方面的技术支持，其一是抽象的协议，也就是技术理论层面的设计；其二是一整套MCP的开发工具，也就是一些库，方便大家进行MCP工具（MCP Server）的开发并构建智能体；其三，MCP还提供了一整套非常丰富的开发生态，由于MCP是一套标准协议，任何MCP工具（MCP Server）都可以无缝接入任何MCP智能体中，也就是你开发的工具我也能用，我开发的工具你也能直接用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f210673c-9901-460e-8dee-edf59d29a1a8",
   "metadata": {
    "id": "f210673c-9901-460e-8dee-edf59d29a1a8"
   },
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250403170307263.png\" alt=\"image-20250403170307263\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feadbc3e-22c3-4155-9e38-616bd5232a1b",
   "metadata": {
    "id": "feadbc3e-22c3-4155-9e38-616bd5232a1b"
   },
   "source": [
    "### 3.MCP+Agents SDK基础调用流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1cc6ca-e2c5-460c-882f-9cb106278efa",
   "metadata": {
    "id": "cb1cc6ca-e2c5-460c-882f-9cb106278efa"
   },
   "source": [
    "&emsp;&emsp;而在新版的Agents SDK中，Agents SDK可以将某个对应的Agent封装为client与外部定义好的server进行通信。基本实现流程如下，\n",
    "\n",
    "（1） 创建MCP客户端项目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rCTzx1idQxw6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7151,
     "status": "ok",
     "timestamp": 1755913240752,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "rCTzx1idQxw6",
    "outputId": "93aa0392-fbda-4534-dc51-6dca71513f11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting uv\n",
      "  Downloading uv-0.8.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Downloading uv-0.8.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: uv\n",
      "Successfully installed uv-0.8.13\n",
      "Initialized project `\u001b[36mmcp-client\u001b[39m` at `\u001b[36m/content/mcp-client\u001b[39m`\n"
     ]
    }
   ],
   "source": [
    "!pip install uv\n",
    "!uv init mcp-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1MrODy6JRSpQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1755917203476,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "1MrODy6JRSpQ",
    "outputId": "3111ceae-2c11-44bd-ff0a-bb6ec9e93162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/mcp-client\n"
     ]
    }
   ],
   "source": [
    "%cd mcp-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CphX0RmJRWPy",
   "metadata": {
    "id": "CphX0RmJRWPy"
   },
   "source": [
    "(2） 创建MCP客户端虚拟环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cgqi8GuMRZJT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7671,
     "status": "ok",
     "timestamp": 1755917217861,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "cgqi8GuMRZJT",
    "outputId": "db448706-7a26-4755-b21c-8cb42bf7b86d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe `--system` flag has no effect, a system Python interpreter is always used in `uv venv`\u001b[0m\n",
      "Using CPython 3.12.11 interpreter at: \u001b[36m/usr/bin/python3\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "\u001b[33m?\u001b[0m \u001b[1mA virtual environment already exists at `.venv`. Do you want to replace it?\u001b[0m \u001b[38;5;8m[y/n]\u001b[0m \u001b[38;5;8m›\u001b[0m \u001b[36myes\u001b[0m\n",
      "\n",
      "\u001b[0J\u001b[32m✔\u001b[0m \u001b[1mA virtual environment already exists at `.venv`. Do you want to replace it?\u001b[0m \u001b[38;5;8m·\u001b[0m \u001b[36myes\u001b[0m\n",
      "\u001b[?25hActivate with: \u001b[32msource .venv/bin/activate\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# 创建虚拟环境\n",
    "!uv venv\n",
    "\n",
    "# 激活虚拟环境\n",
    "!source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XN9WIACCx9yB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 723,
     "status": "ok",
     "timestamp": 1755918021218,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "XN9WIACCx9yB",
    "outputId": "e513115b-c8c0-404e-9109-eeeef9090a0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m55 packages\u001b[0m \u001b[2min 217ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m16 packages\u001b[0m \u001b[2min 389ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m16 packages\u001b[0m \u001b[2min 61ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.51\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.13\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add mcp openai openai-agents python-dotenv IPython #为了支持调用大模型，以及在环境变量中读取API-key等信息，需要先安装如下依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z1vpqZOAyJtd",
   "metadata": {
    "id": "z1vpqZOAyJtd"
   },
   "outputs": [],
   "source": [
    "# 创建 .env 文件\n",
    "!echo \"OPENAI_API_KEY=sk-XXXXX(自己的API-KEY)\" > /content/mcp-client/.env\n",
    "!echo \"BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1\" >> /content/mcp-client/.env\n",
    "!echo \"MODEL=qwen-plus\" >> /content/mcp-client/.env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2Co4FheYQpj_",
   "metadata": {
    "id": "2Co4FheYQpj_"
   },
   "source": [
    "创建名称为`weather_server.py`的天气服务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff346ef7-ab47-4e87-9046-48707cab1769",
   "metadata": {
    "id": "ff346ef7-ab47-4e87-9046-48707cab1769"
   },
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250403173507052.png\" alt=\"image-20250403173507052\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_2_e_eV2NktU",
   "metadata": {
    "id": "_2_e_eV2NktU"
   },
   "source": [
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zfz9ug5aNjRm",
   "metadata": {
    "id": "zfz9ug5aNjRm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import httpx\n",
    "from typing import Any\n",
    "from dotenv import load_dotenv\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# 初始化 MCP 服务器\n",
    "mcp = FastMCP(\"WeatherServer\")\n",
    "# OpenWeather API 配置\n",
    "OPENWEATHER_API_BASE = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "API_KEY = \"XXXXX(自己的API-KEY)\" # 填写你的OpenWeather-API-KEY\n",
    "USER_AGENT = \"weather-app/1.0\"\n",
    "\n",
    "async def fetch_weather(city: str) -> dict[str, Any] | None:\n",
    "  \"\"\"从 OpenWeather API 获取天气信息。\n",
    "  :param city: 城市名称（需使用英文，如 Beijing）\n",
    "  :return: 天气数据字典；若出错返回包含 error 信息的字典\n",
    "  \"\"\"\n",
    "  params = {\n",
    "    \"q\": city,\n",
    "    \"appid\": API_KEY,\n",
    "    \"units\": \"metric\",\n",
    "    \"lang\": \"zh_cn\"\n",
    "  }\n",
    "  headers = {\"User-Agent\": USER_AGENT}\n",
    "\n",
    "\n",
    "  async with httpx.AsyncClient() as client:\n",
    "    try:\n",
    "      response = await client.get(OPENWEATHER_API_BASE, params=params,\n",
    "      headers=headers, timeout=30.0)\n",
    "      response.raise_for_status()\n",
    "      return response.json() # 返回字典类型\n",
    "    except httpx.HTTPStatusError as e:\n",
    "      return {\"error\": f\"HTTP 错误: {e.response.status_code}\"}\n",
    "    except Exception as e:\n",
    "      return {\"error\": f\"请求失败: {str(e)}\"}\n",
    "\n",
    "\n",
    "def format_weather(data: dict[str, Any] | str) -> str:\n",
    "  \"\"\"\n",
    "  将天气数据格式化为易读文本。\n",
    "  :param data: 天气数据（可以是字典或 JSON 字符串）\n",
    "  :return: 格式化后的天气信息字符串\n",
    "  \"\"\"\n",
    "  # 如果传入的是字符串，则先转换为字典\n",
    "  if isinstance(data, str):\n",
    "    try:\n",
    "      data = json.loads(data)\n",
    "    except Exception as e:\n",
    "      return f\"无法解析天气数据: {e}\"\n",
    "  # 如果数据中包含错误信息，直接返回错误提示\n",
    "  if \"error\" in data:\n",
    "    return f\"⚠️ {data['error']}\"\n",
    "  # 提取数据时做容错处理\n",
    "  city = data.get(\"name\", \"未知\")\n",
    "  country = data.get(\"sys\", {}).get(\"country\", \"未知\")\n",
    "  temp = data.get(\"main\", {}).get(\"temp\", \"N/A\")\n",
    "  humidity = data.get(\"main\", {}).get(\"humidity\", \"N/A\")\n",
    "  wind_speed = data.get(\"wind\", {}).get(\"speed\", \"N/A\")\n",
    "  # weather 可能为空列表，因此用 [0] 前先提供默认字典\n",
    "  weather_list = data.get(\"weather\", [{}])\n",
    "  description = weather_list[0].get(\"description\", \"未知\")\n",
    "  return (\n",
    "    f\"🌍 {city}, {country}\\n\"\n",
    "    f\"🌡 温度: {temp}°C\\n\"\n",
    "    f\"💧 湿度: {humidity}%\\n\"\n",
    "    f\"🌬 风速: {wind_speed} m/s\\n\"\n",
    "    f\"🌤 天气: {description}\\n\"\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "async def query_weather(city: str) -> str:\n",
    "  \"\"\"\n",
    "  输入指定城市的英文名称，返回今日天气查询结果。\n",
    "  :param city: 城市名称（需使用英文）\n",
    "  :return: 格式化后的天气信息\n",
    "  \"\"\"\n",
    "  data = await fetch_weather(city)\n",
    "  return format_weather(data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  # 以标准 I/O 方式运行 MCP 服务器\n",
    "  mcp.run(transport='stdio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec636a0-3901-445a-a2a9-438ab1b0dccc",
   "metadata": {
    "id": "dec636a0-3901-445a-a2a9-438ab1b0dccc"
   },
   "source": [
    "创建名称为client.py的客户端，然后导入代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c577be4f-6118-4e88-a4af-00b2f98970b9",
   "metadata": {
    "id": "c577be4f-6118-4e88-a4af-00b2f98970b9"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "from agents import OpenAIChatCompletionsModel,Agent,Runner,set_default_openai_client\n",
    "from agents.model_settings import ModelSettings\n",
    "from agents import function_tool\n",
    "import requests,json\n",
    "\n",
    "from agents import (\n",
    "    Agent,\n",
    "    HandoffOutputItem,\n",
    "    ItemHelpers,\n",
    "    MessageOutputItem,\n",
    "    RunContextWrapper,\n",
    "    Runner,\n",
    "    ToolCallItem,\n",
    "    ToolCallOutputItem,\n",
    "    TResponseInputItem,\n",
    "    function_tool,\n",
    "    handoff,\n",
    "    trace,\n",
    ")\n",
    "from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n",
    "from agents.mcp import MCPServer, MCPServerStdio\n",
    "\n",
    "\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\") # 读取 OpenAI API Key\n",
    "base_url = os.getenv(\"BASE_URL\") # 读取 BASE YRL\n",
    "model = os.getenv(\"MODEL\") # 读取 model\n",
    "if not openai_api_key:\n",
    "  raise ValueError(\"❌ 未找到 OpenAI API Key，请在 .env 文件中设置OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=openai_api_key, base_url=base_url)\n",
    "\n",
    "external_client = AsyncOpenAI(\n",
    "    base_url = base_url,\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "set_default_openai_client(external_client)\n",
    "\n",
    "qianwen_model = OpenAIChatCompletionsModel(\n",
    "    model=model,\n",
    "    openai_client=external_client)\n",
    "\n",
    "async def run(mcp_server: MCPServer):\n",
    "\n",
    "    agent = Agent(\n",
    "        name=\"Assistant\",\n",
    "        instructions=\"你是一名助人为乐的助手\",\n",
    "        mcp_servers=[mcp_server],\n",
    "        model=qianwen_model\n",
    "    )\n",
    "\n",
    "    message = \"请帮我查询北京今天天气如何？\"\n",
    "    print(f\"Running: {message}\")\n",
    "    result = await Runner.run(starting_agent=agent, input=message)\n",
    "    print(result.final_output)\n",
    "\n",
    "async def mcp_run():\n",
    "    async with MCPServerStdio(\n",
    "        name=\"Weather Server\",\n",
    "        cache_tools_list=True,\n",
    "        params = {\"command\": \"uv\",\"args\": [\"run\", \"weather_server.py\"]}\n",
    "    ) as server:\n",
    "        await run(server)\n",
    "\n",
    "async def main():\n",
    "   await mcp_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca11439-4981-483a-bdcc-4f05039e99e8",
   "metadata": {
    "id": "dca11439-4981-483a-bdcc-4f05039e99e8"
   },
   "source": [
    "具体解释如下：同时定义Agent+MCP运行函数，要求带入MCPServer对象，且带入mcp_servers中，作为类似tools参数带入到当前Agent运行过程中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49691e9-9c56-42b5-afdd-2ec49ce30878",
   "metadata": {
    "id": "d49691e9-9c56-42b5-afdd-2ec49ce30878"
   },
   "outputs": [],
   "source": [
    "async def run(mcp_server: MCPServer):\n",
    "\n",
    "    agent = Agent(\n",
    "        name=\"Assistant\",\n",
    "        instructions=\"你是一名助人为乐的助手\",\n",
    "        mcp_servers=[mcp_server],\n",
    "        model=qianwen_model\n",
    "    )\n",
    "\n",
    "    message = \"请帮我查询北京今天天气如何？\"\n",
    "    print(f\"Running: {message}\")\n",
    "    result = await Runner.run(starting_agent=agent, input=message)\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8208ee-e1a3-43c2-bb9e-83a3e7c13dcc",
   "metadata": {
    "id": "5a8208ee-e1a3-43c2-bb9e-83a3e7c13dcc"
   },
   "source": [
    "然后创建mcp_run函数，负责开启外部server并运行Agent："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b3f5fa-5e26-4a87-a7eb-a5d9ee92abdf",
   "metadata": {
    "id": "d1b3f5fa-5e26-4a87-a7eb-a5d9ee92abdf"
   },
   "outputs": [],
   "source": [
    "async def mcp_run():\n",
    "    async with MCPServerStdio(\n",
    "        name=\"Weather Server\",\n",
    "        cache_tools_list=True,\n",
    "        params = {\"command\": \"uv\",\"args\": [\"run\", \"weather_server.py\"]}\n",
    "    ) as server:\n",
    "        await run(server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a64800c-0ed5-45b5-a685-f90b0aa5df7a",
   "metadata": {
    "id": "6a64800c-0ed5-45b5-a685-f90b0aa5df7a"
   },
   "source": [
    "✅ 关键组件解释：\n",
    "\n",
    "- `async with MCPServerStdio(...) as server:`  \n",
    "  启动一个 MCP 工具服务器进程，使用标准输入输出（`stdio`）作为通信协议，并在上下文中运行（退出时会自动关闭）。\n",
    "\n",
    "- `name=\"Weather Server\"`  \n",
    "  给这个 MCP Server 起名为“天气服务器”，这只是用于日志和识别用的标识符。\n",
    "\n",
    "- `cache_tools_list=True`  \n",
    "  意思是：首次加载工具时缓存工具列表，后续不需要重新请求工具元数据（提升效率）。\n",
    "\n",
    "- `params = {\"command\": \"uv\", \"args\": [\"run\", \"weather_server.py\"]}`  \n",
    "  这是启动 MCP 工具服务器的 **命令行参数**，等价于在命令行里运行：\n",
    "  ```bash\n",
    "  uv run weather_server.py\n",
    "  ```\n",
    "  - `uv`：同样使用[uv](https://github.com/astral-sh/uv)，是一个快速的 Python 包和环境管理器，比 pip/venv 更高效。\n",
    "  - `run weather_server.py`：运行一个你定义好的MCP server。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa31d93-0ccd-4807-b785-d74ad712a033",
   "metadata": {
    "id": "4aa31d93-0ccd-4807-b785-d74ad712a033"
   },
   "source": [
    "最后测试运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1Hqrj11DOqeq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1452,
     "status": "ok",
     "timestamp": 1755917277739,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "1Hqrj11DOqeq",
    "outputId": "0532175d-99bc-4c3f-ac62-de2ace4d6c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 127ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 118ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 84ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 82ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 97ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 99ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 92ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 110ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install openai==1.99.9\n",
    "!uv pip install openai-agents\n",
    "!uv pip install mcp\n",
    "!uv pip install httpx\n",
    "!uv pip install pydantic\n",
    "!uv pip install python-dotenv\n",
    "!uv pip install agents\n",
    "!uv pip install mcp-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C_qQONFrMoQH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7641,
     "status": "ok",
     "timestamp": 1755918090950,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "C_qQONFrMoQH",
    "outputId": "9c2c99b9-e1b1-46b5-bc5e-0249bc841e02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: 请帮我查询北京今天天气如何？\n",
      "Processing request of type ListToolsRequest\n",
      "Processing request of type CallToolRequest\n",
      "HTTP Request: GET https://api.openweathermap.org/data/2.5/weather?q=Beijing&appid=11e9adb827a70b8bbdee0f3e31270429&units=metric&lang=zh_cn \"HTTP/1.1 200 OK\"\n",
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: sk-21247***********************92e9. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n",
      "北京今天的天气情况如下：\n",
      "\n",
      "- **温度**: 24.94°C  \n",
      "- **湿度**: 62%  \n",
      "- **风速**: 3.85 m/s  \n",
      "- **天气**: 阴，多云  \n",
      "\n",
      "希望这些信息对你有帮助！\n",
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: sk-21247***********************92e9. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!uv run client.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5eef1d-b203-4096-be1d-c2383ad82bc2",
   "metadata": {
    "id": "2c5eef1d-b203-4096-be1d-c2383ad82bc2"
   },
   "source": [
    "### 4. Agents SDK接入更多开源MCP服务器流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee1fb56-ac4a-452e-8be4-1886018036a5",
   "metadata": {
    "id": "8ee1fb56-ac4a-452e-8be4-1886018036a5"
   },
   "source": [
    "&emsp;&emsp;若要采用MCP技术栈，最核心的便利就在于可以快速接入海量MCP开源服务器，无需反复开发，即可快速丰富当前Agent功能。热门MCP server合集地址如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bfdf7a-6a5c-4eef-a477-3d0c89a51d27",
   "metadata": {
    "id": "e9bfdf7a-6a5c-4eef-a477-3d0c89a51d27"
   },
   "source": [
    "- Model Context Protocol servers: https://github.com/modelcontextprotocol/servers\n",
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250403174645233.png\" alt=\"image-20250403174645233\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15bf5ab-311e-4c11-8bd3-24e6f0f7b878",
   "metadata": {
    "id": "a15bf5ab-311e-4c11-8bd3-24e6f0f7b878"
   },
   "source": [
    "- Awesome MCP Servers: https://github.com/punkpeye/awesome-mcp-servers\n",
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250403174514932.png\" alt=\"image-20250403174514932\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1299c87-c96a-48df-a131-8f10eb494e9f",
   "metadata": {
    "id": "b1299c87-c96a-48df-a131-8f10eb494e9f"
   },
   "source": [
    "- MCP导航： https://mcp.so/\n",
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250403174757712.png\" alt=\"image-20250403174757712\" style=\"zoom:50%;\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb44f7fe-6036-46bb-a09e-1842e31b550b",
   "metadata": {
    "id": "eb44f7fe-6036-46bb-a09e-1842e31b550b"
   },
   "source": [
    "接下来我们就先尝试接入一个开源的、开发人员常用的MCP服务器——mcp-server-git。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba3ec39-9bcd-4dfa-98ec-39e84603c061",
   "metadata": {
    "id": "2ba3ec39-9bcd-4dfa-98ec-39e84603c061"
   },
   "source": [
    "- mcp-server-git：https://github.com/modelcontextprotocol/servers/tree/main/src/git\n",
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250403175004931.png\" alt=\"image-20250403175004931\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BclWhFmvD1cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1755921226053,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "BclWhFmvD1cf",
    "outputId": "2678c728-f545-4a32-c7c3-3302ec927dc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K  \u001b[31m×\u001b[0m Failed to resolve `--with` requirement\n",
      "\u001b[31m  ╰─▶ \u001b[0mGit operation failed\n"
     ]
    }
   ],
   "source": [
    "!uvx git+https://github.com/modelcontextprotocol/servers/tree/main/src/git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009f1cc2-aeab-4faf-93ac-74ddf9d3cee1",
   "metadata": {
    "id": "009f1cc2-aeab-4faf-93ac-74ddf9d3cee1"
   },
   "source": [
    "##### 📌 MCP-Server-Git 简介\n",
    "\n",
    "`mcp-server-git` 是一个遵循 **Model Context Protocol (MCP)** 的 Git 操作服务器，专为大语言模型与 Git 仓库的交互而设计。通过该服务，模型可以安全、结构化地完成 Git 操作，包括状态查询、差异比较、提交更改、分支管理等，从而实现自动化代码管理与协作。\n",
    "\n",
    "\n",
    "✨ 核心功能包括：\n",
    "\n",
    "- **查询仓库状态**：获取当前工作区和暂存区的变动情况（`git_status`、`git_diff_unstaged`、`git_diff_staged`）\n",
    "- **版本比较**：支持分支或提交之间的差异查看（`git_diff`）\n",
    "- **代码提交与暂存管理**：支持新增、暂存、撤销暂存、更改提交（`git_add`、`git_reset`、`git_commit`）\n",
    "- **日志查询与历史查看**：获取提交历史、查看具体提交内容（`git_log`、`git_show`）\n",
    "- **分支操作**：新建分支、切换分支（`git_create_branch`、`git_checkout`）\n",
    "- **仓库初始化**：支持新建空 Git 仓库（`git_init`）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96874061-8152-403a-9a2f-929cd20f70d2",
   "metadata": {
    "id": "96874061-8152-403a-9a2f-929cd20f70d2"
   },
   "source": [
    "##### 🚀 调用方式\n",
    "✅ 使用 `uvenv` 快速启动（推荐方式）\n",
    "\n",
    "无需安装，只需一行命令即可运行：\n",
    "\n",
    "```bash\n",
    "uvenv run mcp-server-git\n",
    "```\n",
    "\n",
    "首次运行会从 PyPI 下载并缓存，后续启动速度更快。\n",
    "\n",
    "\n",
    "📡 接口调用格式（示例）\n",
    "\n",
    "以 `git_status` 为例，MCP 工具调用格式如下：\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"tool\": \"git_status\",\n",
    "  \"input\": {\n",
    "    \"repo_path\": \"/path/to/your/git/repo\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "服务将返回 Git 工作目录当前状态的文本描述。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb78ec-75dc-4e63-a8d9-4fb6b1367504",
   "metadata": {
    "id": "cbbb78ec-75dc-4e63-a8d9-4fb6b1367504"
   },
   "source": [
    "- uvx（已弃用）/ uvenv 工具安装与使用指南（Ubuntu）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51e882-ca9c-4b04-9d36-909a5c60d1ac",
   "metadata": {
    "id": "6b51e882-ca9c-4b04-9d36-909a5c60d1ac"
   },
   "source": [
    "`uvx`（现已由 `uvenv` 取代）是一个基于 Python 的零安装运行工具，可快速运行 Python 包，而无需手动安装或污染系统环境。\n",
    "\n",
    "1. uvenv 安装方法（Ubuntu）\n",
    "\n",
    "打开终端，运行以下命令自动安装最新版 `uv`（含 `uvenv`）：\n",
    "\n",
    "```bash\n",
    "curl -Ls https://astral.sh/uv/install.sh | sh\n",
    "```\n",
    "\n",
    "或使用 `wget` 命令安装：\n",
    "\n",
    "```bash\n",
    "wget -qO- https://astral.sh/uv/install.sh | sh\n",
    "```\n",
    "\n",
    "安装完成后，验证是否安装成功：\n",
    "\n",
    "```bash\n",
    "uv --version\n",
    "uvenv --help\n",
    "```\n",
    "\n",
    "🔁 可选：通过 pip 安装（不推荐）\n",
    "\n",
    "```bash\n",
    "pip install uv\n",
    "```\n",
    "\n",
    "虽然可以使用 pip 安装 `uv`，但官方推荐使用上面的安装脚本，因为：\n",
    "- 安装的是预编译二进制版本，性能更好\n",
    "- 功能更完整\n",
    "- 自动将可执行文件添加到环境路径\n",
    "\n",
    "\n",
    "2. uvenv 功能说明\n",
    "\n",
    "- **无需提前安装**：`uvenv` 自动从 PyPI 拉取并运行 Python 包。\n",
    "- **隔离环境**：每次执行均为临时环境，避免污染系统全局环境。\n",
    "- **缓存机制**：首次拉取后自动缓存，后续使用直接读取缓存，提高运行速度。\n",
    "- **用途广泛**：适用于快速测试、命令行工具临时使用以及 Python 脚本的隔离执行。\n",
    "\n",
    "\n",
    "3. uvenv 基本使用方法\n",
    "\n",
    "使用语法\n",
    "\n",
    "```bash\n",
    "uvenv run <package-name>\n",
    "```\n",
    "\n",
    "示例：运行 `mcp-server-git`\n",
    "\n",
    "首次运行会自动从 PyPI 下载并缓存：\n",
    "\n",
    "```bash\n",
    "uvenv run mcp-server-git\n",
    "```\n",
    "\n",
    "再次运行则直接使用缓存，速度更快：\n",
    "\n",
    "```bash\n",
    "uvenv run mcp-server-git\n",
    "```\n",
    "\n",
    "⚠️ 更新缓存中的包\n",
    "\n",
    "默认情况下，`uvenv` 不会自动检测和使用 PyPI 上的新版本。如果想强制使用最新版本，可以：\n",
    "\n",
    "- 清理缓存后重新运行：\n",
    "\n",
    "```bash\n",
    "uv cache clear\n",
    "uvenv run mcp-server-git\n",
    "```\n",
    "\n",
    "\n",
    "4. 常用操作\n",
    "\n",
    "- **查看缓存位置**：\n",
    "\n",
    "```bash\n",
    "ls ~/.cache/uv\n",
    "```\n",
    "\n",
    "- **清理缓存**（若需要）：\n",
    "\n",
    "```bash\n",
    "uv cache clear\n",
    "```\n",
    "\n",
    "- **升级 uv/uvenv 工具**：\n",
    "\n",
    "```bash\n",
    "uv self update\n",
    "```\n",
    "\n",
    "- **从 uvx 迁移提示**：如果你看到如下提示：\n",
    "\n",
    "```bash\n",
    "Deprecation Message: `uvx` is deprecated in favor of `uvenv`.\n",
    "```\n",
    "说明你已成功迁移到新版，请使用 `uvenv run <package>` 来代替原来的 `uvx <package>` 命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nnWdK6neWOPN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4505,
     "status": "ok",
     "timestamp": 1755926041848,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "nnWdK6neWOPN",
    "outputId": "45b18839-c6a6-44ac-a9a0-fa12d8547aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uv in /usr/local/lib/python3.12/dist-packages (0.8.13)\n"
     ]
    }
   ],
   "source": [
    "!pip install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cB2oIpQbNFUx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1214,
     "status": "ok",
     "timestamp": 1755919854464,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "cB2oIpQbNFUx",
    "outputId": "22d80dd8-d8b5-4e72-e0db-1c29c15026f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading uv 0.8.13 x86_64-unknown-linux-gnu\n",
      "no checksums to verify\n",
      "installing to /usr/local/bin\n",
      "  uv\n",
      "  uvx\n",
      "everything's installed!\n"
     ]
    }
   ],
   "source": [
    "!wget -qO- https://astral.sh/uv/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UhK177r-NM_h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1755921245300,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "UhK177r-NM_h",
    "outputId": "cfd0c170-4015-4157-f50a-208b06de52d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uv 0.8.13\n",
      "Run a command provided by a Python package.\n",
      "\n",
      "\u001b[1m\u001b[32mUsage:\u001b[0m uvx [OPTIONS] [COMMAND]\n",
      "\n",
      "\u001b[1m\u001b[32mOptions:\u001b[0m\n",
      "      \u001b[1m\u001b[36m--from\u001b[0m\u001b[36m \u001b[0m\u001b[36m<FROM>\u001b[0m\n",
      "          Use the given package to provide the command\n",
      "  \u001b[1m\u001b[36m-w\u001b[0m, \u001b[1m\u001b[36m--with\u001b[0m\u001b[36m \u001b[0m\u001b[36m<WITH>\u001b[0m\n",
      "          Run with the given packages installed\n",
      "      \u001b[1m\u001b[36m--with-editable\u001b[0m\u001b[36m \u001b[0m\u001b[36m<WITH_EDITABLE>\u001b[0m\n",
      "          Run with the given packages installed in editable mode\n",
      "      \u001b[1m\u001b[36m--with-requirements\u001b[0m\u001b[36m \u001b[0m\u001b[36m<WITH_REQUIREMENTS>\u001b[0m\n",
      "          Run with all packages listed in the given `requirements.txt` files\n",
      "  \u001b[1m\u001b[36m-c\u001b[0m, \u001b[1m\u001b[36m--constraints\u001b[0m\u001b[36m \u001b[0m\u001b[36m<CONSTRAINTS>\u001b[0m\n",
      "          Constrain versions using the given requirements files [env: UV_CONSTRAINT=]\n",
      "  \u001b[1m\u001b[36m-b\u001b[0m, \u001b[1m\u001b[36m--build-constraints\u001b[0m\u001b[36m \u001b[0m\u001b[36m<BUILD_CONSTRAINTS>\u001b[0m\n",
      "          Constrain build dependencies using the given requirements files when building source\n",
      "          distributions [env: UV_BUILD_CONSTRAINT=]\n",
      "      \u001b[1m\u001b[36m--overrides\u001b[0m\u001b[36m \u001b[0m\u001b[36m<OVERRIDES>\u001b[0m\n",
      "          Override versions using the given requirements files [env: UV_OVERRIDE=]\n",
      "      \u001b[1m\u001b[36m--isolated\u001b[0m\n",
      "          Run the tool in an isolated virtual environment, ignoring any already-installed tools\n",
      "      \u001b[1m\u001b[36m--env-file\u001b[0m\u001b[36m \u001b[0m\u001b[36m<ENV_FILE>\u001b[0m\n",
      "          Load environment variables from a `.env` file [env: UV_ENV_FILE=]\n",
      "      \u001b[1m\u001b[36m--no-env-file\u001b[0m\n",
      "          Avoid reading environment variables from a `.env` file [env: UV_NO_ENV_FILE=]\n",
      "  \u001b[1m\u001b[36m-V\u001b[0m, \u001b[1m\u001b[36m--version\u001b[0m\n",
      "          Display the uvx version\n",
      "\n",
      "\u001b[1m\u001b[32mIndex options:\u001b[0m\n",
      "      \u001b[1m\u001b[36m--index\u001b[0m\u001b[36m \u001b[0m\u001b[36m<INDEX>\u001b[0m\n",
      "          The URLs to use when resolving dependencies, in addition to the default index [env:\n",
      "          UV_INDEX=]\n",
      "      \u001b[1m\u001b[36m--default-index\u001b[0m\u001b[36m \u001b[0m\u001b[36m<DEFAULT_INDEX>\u001b[0m\n",
      "          The URL of the default package index (by default: <https://pypi.org/simple>) [env:\n",
      "          UV_DEFAULT_INDEX=]\n",
      "  \u001b[1m\u001b[36m-i\u001b[0m, \u001b[1m\u001b[36m--index-url\u001b[0m\u001b[36m \u001b[0m\u001b[36m<INDEX_URL>\u001b[0m\n",
      "          (Deprecated: use `--default-index` instead) The URL of the Python package index (by\n",
      "          default: <https://pypi.org/simple>) [env: UV_INDEX_URL=]\n",
      "      \u001b[1m\u001b[36m--extra-index-url\u001b[0m\u001b[36m \u001b[0m\u001b[36m<EXTRA_INDEX_URL>\u001b[0m\n",
      "          (Deprecated: use `--index` instead) Extra URLs of package indexes to use, in addition to\n",
      "          `--index-url` [env: UV_EXTRA_INDEX_URL=]\n",
      "  \u001b[1m\u001b[36m-f\u001b[0m, \u001b[1m\u001b[36m--find-links\u001b[0m\u001b[36m \u001b[0m\u001b[36m<FIND_LINKS>\u001b[0m\n",
      "          Locations to search for candidate distributions, in addition to those found in the\n",
      "          registry indexes [env: UV_FIND_LINKS=]\n",
      "      \u001b[1m\u001b[36m--no-index\u001b[0m\n",
      "          Ignore the registry index (e.g., PyPI), instead relying on direct URL dependencies and\n",
      "          those provided via `--find-links`\n",
      "      \u001b[1m\u001b[36m--index-strategy\u001b[0m\u001b[36m \u001b[0m\u001b[36m<INDEX_STRATEGY>\u001b[0m\n",
      "          The strategy to use when resolving against multiple index URLs [env: UV_INDEX_STRATEGY=]\n",
      "          [possible values: first-index, unsafe-first-match, unsafe-best-match]\n",
      "      \u001b[1m\u001b[36m--keyring-provider\u001b[0m\u001b[36m \u001b[0m\u001b[36m<KEYRING_PROVIDER>\u001b[0m\n",
      "          Attempt to use `keyring` for authentication for index URLs [env: UV_KEYRING_PROVIDER=]\n",
      "          [possible values: disabled, subprocess]\n",
      "\n",
      "\u001b[1m\u001b[32mResolver options:\u001b[0m\n",
      "  \u001b[1m\u001b[36m-U\u001b[0m, \u001b[1m\u001b[36m--upgrade\u001b[0m\n",
      "          Allow package upgrades, ignoring pinned versions in any existing output file. Implies\n",
      "          `--refresh`\n",
      "  \u001b[1m\u001b[36m-P\u001b[0m, \u001b[1m\u001b[36m--upgrade-package\u001b[0m\u001b[36m \u001b[0m\u001b[36m<UPGRADE_PACKAGE>\u001b[0m\n",
      "          Allow upgrades for a specific package, ignoring pinned versions in any existing output\n",
      "          file. Implies `--refresh-package`\n",
      "      \u001b[1m\u001b[36m--resolution\u001b[0m\u001b[36m \u001b[0m\u001b[36m<RESOLUTION>\u001b[0m\n",
      "          The strategy to use when selecting between the different compatible versions for a given\n",
      "          package requirement [env: UV_RESOLUTION=] [possible values: highest, lowest,\n",
      "          lowest-direct]\n",
      "      \u001b[1m\u001b[36m--prerelease\u001b[0m\u001b[36m \u001b[0m\u001b[36m<PRERELEASE>\u001b[0m\n",
      "          The strategy to use when considering pre-release versions [env: UV_PRERELEASE=] [possible\n",
      "          values: disallow, allow, if-necessary, explicit, if-necessary-or-explicit]\n",
      "      \u001b[1m\u001b[36m--fork-strategy\u001b[0m\u001b[36m \u001b[0m\u001b[36m<FORK_STRATEGY>\u001b[0m\n",
      "          The strategy to use when selecting multiple versions of a given package across Python\n",
      "          versions and platforms [env: UV_FORK_STRATEGY=] [possible values: fewest, requires-python]\n",
      "      \u001b[1m\u001b[36m--exclude-newer\u001b[0m\u001b[36m \u001b[0m\u001b[36m<EXCLUDE_NEWER>\u001b[0m\n",
      "          Limit candidate packages to those that were uploaded prior to the given date [env:\n",
      "          UV_EXCLUDE_NEWER=]\n",
      "      \u001b[1m\u001b[36m--exclude-newer-package\u001b[0m\u001b[36m \u001b[0m\u001b[36m<EXCLUDE_NEWER_PACKAGE>\u001b[0m\n",
      "          Limit candidate packages for specific packages to those that were uploaded prior to the\n",
      "          given date\n",
      "      \u001b[1m\u001b[36m--no-sources\u001b[0m\n",
      "          Ignore the `tool.uv.sources` table when resolving dependencies. Used to lock against the\n",
      "          standards-compliant, publishable package metadata, as opposed to using any workspace, Git,\n",
      "          URL, or local path sources\n",
      "\n",
      "\u001b[1m\u001b[32mInstaller options:\u001b[0m\n",
      "      \u001b[1m\u001b[36m--reinstall\u001b[0m\n",
      "          Reinstall all packages, regardless of whether they're already installed. Implies\n",
      "          `--refresh`\n",
      "      \u001b[1m\u001b[36m--reinstall-package\u001b[0m\u001b[36m \u001b[0m\u001b[36m<REINSTALL_PACKAGE>\u001b[0m\n",
      "          Reinstall a specific package, regardless of whether it's already installed. Implies\n",
      "          `--refresh-package`\n",
      "      \u001b[1m\u001b[36m--link-mode\u001b[0m\u001b[36m \u001b[0m\u001b[36m<LINK_MODE>\u001b[0m\n",
      "          The method to use when installing packages from the global cache [env: UV_LINK_MODE=]\n",
      "          [possible values: clone, copy, hardlink, symlink]\n",
      "      \u001b[1m\u001b[36m--compile-bytecode\u001b[0m\n",
      "          Compile Python files to bytecode after installation [env: UV_COMPILE_BYTECODE=]\n",
      "\n",
      "\u001b[1m\u001b[32mBuild options:\u001b[0m\n",
      "  \u001b[1m\u001b[36m-C\u001b[0m, \u001b[1m\u001b[36m--config-setting\u001b[0m\u001b[36m \u001b[0m\u001b[36m<CONFIG_SETTING>\u001b[0m\n",
      "          Settings to pass to the PEP 517 build backend, specified as `KEY=VALUE` pairs\n",
      "      \u001b[1m\u001b[36m--config-settings-package\u001b[0m\u001b[36m \u001b[0m\u001b[36m<CONFIG_SETTINGS_PACKAGE>\u001b[0m\n",
      "          Settings to pass to the PEP 517 build backend for a specific package, specified as\n",
      "          `PACKAGE:KEY=VALUE` pairs\n",
      "      \u001b[1m\u001b[36m--no-build-isolation\u001b[0m\n",
      "          Disable isolation when building source distributions [env: UV_NO_BUILD_ISOLATION=]\n",
      "      \u001b[1m\u001b[36m--no-build-isolation-package\u001b[0m\u001b[36m \u001b[0m\u001b[36m<NO_BUILD_ISOLATION_PACKAGE>\u001b[0m\n",
      "          Disable isolation when building source distributions for a specific package\n",
      "      \u001b[1m\u001b[36m--no-build\u001b[0m\n",
      "          Don't build source distributions [env: UV_NO_BUILD=]\n",
      "      \u001b[1m\u001b[36m--no-build-package\u001b[0m\u001b[36m \u001b[0m\u001b[36m<NO_BUILD_PACKAGE>\u001b[0m\n",
      "          Don't build source distributions for a specific package [env: UV_NO_BUILD_PACKAGE=]\n",
      "      \u001b[1m\u001b[36m--no-binary\u001b[0m\n",
      "          Don't install pre-built wheels [env: UV_NO_BINARY=]\n",
      "      \u001b[1m\u001b[36m--no-binary-package\u001b[0m\u001b[36m \u001b[0m\u001b[36m<NO_BINARY_PACKAGE>\u001b[0m\n",
      "          Don't install pre-built wheels for a specific package [env: UV_NO_BINARY_PACKAGE=]\n",
      "\n",
      "\u001b[1m\u001b[32mCache options:\u001b[0m\n",
      "  \u001b[1m\u001b[36m-n\u001b[0m, \u001b[1m\u001b[36m--no-cache\u001b[0m\n",
      "          Avoid reading from or writing to the cache, instead using a temporary directory for the\n",
      "          duration of the operation [env: UV_NO_CACHE=]\n",
      "      \u001b[1m\u001b[36m--cache-dir\u001b[0m\u001b[36m \u001b[0m\u001b[36m<CACHE_DIR>\u001b[0m\n",
      "          Path to the cache directory [env: UV_CACHE_DIR=]\n",
      "      \u001b[1m\u001b[36m--refresh\u001b[0m\n",
      "          Refresh all cached data\n",
      "      \u001b[1m\u001b[36m--refresh-package\u001b[0m\u001b[36m \u001b[0m\u001b[36m<REFRESH_PACKAGE>\u001b[0m\n",
      "          Refresh cached data for a specific package\n",
      "\n",
      "\u001b[1m\u001b[32mPython options:\u001b[0m\n",
      "  \u001b[1m\u001b[36m-p\u001b[0m, \u001b[1m\u001b[36m--python\u001b[0m\u001b[36m \u001b[0m\u001b[36m<PYTHON>\u001b[0m      The Python interpreter to use to build the run environment. [env:\n",
      "                             UV_PYTHON=]\n",
      "      \u001b[1m\u001b[36m--managed-python\u001b[0m       Require use of uv-managed Python versions [env: UV_MANAGED_PYTHON=]\n",
      "      \u001b[1m\u001b[36m--no-managed-python\u001b[0m    Disable use of uv-managed Python versions [env: UV_NO_MANAGED_PYTHON=]\n",
      "      \u001b[1m\u001b[36m--no-python-downloads\u001b[0m  Disable automatic downloads of Python. [env:\n",
      "                             \"UV_PYTHON_DOWNLOADS=never\"]\n",
      "\n",
      "\u001b[1m\u001b[32mGlobal options:\u001b[0m\n",
      "  \u001b[1m\u001b[36m-q\u001b[0m, \u001b[1m\u001b[36m--quiet\u001b[0m\u001b[36m...\u001b[0m\n",
      "          Use quiet output\n",
      "  \u001b[1m\u001b[36m-v\u001b[0m, \u001b[1m\u001b[36m--verbose\u001b[0m\u001b[36m...\u001b[0m\n",
      "          Use verbose output\n",
      "      \u001b[1m\u001b[36m--color\u001b[0m\u001b[36m \u001b[0m\u001b[36m<COLOR_CHOICE>\u001b[0m\n",
      "          Control the use of color in output [possible values: auto, always, never]\n",
      "      \u001b[1m\u001b[36m--native-tls\u001b[0m\n",
      "          Whether to load TLS certificates from the platform's native certificate store [env:\n",
      "          UV_NATIVE_TLS=]\n",
      "      \u001b[1m\u001b[36m--offline\u001b[0m\n",
      "          Disable network access [env: UV_OFFLINE=]\n",
      "      \u001b[1m\u001b[36m--allow-insecure-host\u001b[0m\u001b[36m \u001b[0m\u001b[36m<ALLOW_INSECURE_HOST>\u001b[0m\n",
      "          Allow insecure connections to a host [env: UV_INSECURE_HOST=]\n",
      "      \u001b[1m\u001b[36m--no-progress\u001b[0m\n",
      "          Hide all progress outputs [env: UV_NO_PROGRESS=]\n",
      "      \u001b[1m\u001b[36m--directory\u001b[0m\u001b[36m \u001b[0m\u001b[36m<DIRECTORY>\u001b[0m\n",
      "          Change to the given directory prior to running the command\n",
      "      \u001b[1m\u001b[36m--project\u001b[0m\u001b[36m \u001b[0m\u001b[36m<PROJECT>\u001b[0m\n",
      "          Run the command within the given project directory [env: UV_PROJECT=]\n",
      "      \u001b[1m\u001b[36m--config-file\u001b[0m\u001b[36m \u001b[0m\u001b[36m<CONFIG_FILE>\u001b[0m\n",
      "          The path to a `uv.toml` file to use for configuration [env: UV_CONFIG_FILE=]\n",
      "      \u001b[1m\u001b[36m--no-config\u001b[0m\n",
      "          Avoid discovering configuration files (`pyproject.toml`, `uv.toml`) [env: UV_NO_CONFIG=]\n",
      "  \u001b[1m\u001b[36m-h\u001b[0m, \u001b[1m\u001b[36m--help\u001b[0m\n",
      "          Display the concise help for this command\n",
      "\n",
      "Use `uv help tool run` for more details.\n"
     ]
    }
   ],
   "source": [
    "!uv --version\n",
    "!uvx --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5_n4sQ96EHsq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1949,
     "status": "ok",
     "timestamp": 1755921675767,
     "user": {
      "displayName": "宫丽娜",
      "userId": "06271344955490796779"
     },
     "user_tz": -480
    },
    "id": "5_n4sQ96EHsq",
    "outputId": "818010e6-1a49-4ca8-874e-527ecc80450f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'servers'...\n",
      "remote: Enumerating objects: 12176, done.\u001b[K\n",
      "remote: Counting objects: 100% (230/230), done.\u001b[K\n",
      "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
      "remote: Total 12176 (delta 201), reused 136 (delta 135), pack-reused 11946 (from 3)\u001b[K\n",
      "Receiving objects: 100% (12176/12176), 25.71 MiB | 36.72 MiB/s, done.\n",
      "Resolving deltas: 100% (7838/7838), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/modelcontextprotocol/servers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w1N-AV1ZK-4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1N-AV1ZK-4b",
    "outputId": "be3b221c-5546-4aff-c138-0bfe0e566bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!uv --directory /content/servers/src/git run mcp-server-git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TDINQlekYXR_",
   "metadata": {
    "id": "TDINQlekYXR_"
   },
   "source": [
    "创建脚本.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516dd7d4-0659-4749-bd89-8c5389a84f7c",
   "metadata": {
    "id": "516dd7d4-0659-4749-bd89-8c5389a84f7c"
   },
   "source": [
    "```python\n",
    "import asyncio\n",
    "import shutil\n",
    "\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.mcp import MCPServer, MCPServerStdio\n",
    "\n",
    "\n",
    "async def run(mcp_server: MCPServer, directory_path: str):\n",
    "    agent = Agent(\n",
    "        name=\"Assistant\",\n",
    "        instructions=f\"Answer questions about the git repository at {directory_path}, use that for repo_path\",\n",
    "        mcp_servers=[mcp_server],\n",
    "        model=deepseek_model\n",
    "    )\n",
    "\n",
    "    message = \"请帮我介绍下这个项目。\"\n",
    "    print(\"\\n\" + \"-\" * 40)\n",
    "    print(f\"Running: {message}\")\n",
    "    result = await Runner.run(starting_agent=agent, input=message)\n",
    "    print(result.final_output)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    async with MCPServerStdio(\n",
    "        cache_tools_list=True,\n",
    "        params={\"command\": \"uvenv\", \"args\": [\"run\", \"mcp-server-git\"]},\n",
    "    ) as server:\n",
    "        await run(server, directory_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not shutil.which(\"uvenv\"):\n",
    "        raise RuntimeError(\"uvx is not installed. Please install it with `pip install uvx`.\")\n",
    "\n",
    "    asyncio.run(main())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9acfdb-e442-457b-b774-e1b75e65c70e",
   "metadata": {
    "id": "3f9acfdb-e442-457b-b774-e1b75e65c70e"
   },
   "source": [
    "### (2). Agents SDK接入多个MCP服务器流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91214aba-d68f-4e42-adea-b05d8d19ceff",
   "metadata": {
    "id": "91214aba-d68f-4e42-adea-b05d8d19ceff"
   },
   "source": [
    "&emsp;&emsp;接下来我们继续介绍如何将Agents SDK同时接入多个MCP服务器，理论上，MCP一个服务器能同时运行多个外部函数，而一个MCP Client则可以连接多个MCP服务器："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d6f31-05fe-426e-be90-59b2ff67ce7f",
   "metadata": {
    "id": "d74d6f31-05fe-426e-be90-59b2ff67ce7f"
   },
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250403183654681.png\" alt=\"image-20250403183654681\" style=\"zoom:33%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169bbf0d-2ff7-4561-8b70-dfe6a09a0b64",
   "metadata": {
    "id": "169bbf0d-2ff7-4561-8b70-dfe6a09a0b64"
   },
   "source": [
    "而Agents SDK本身也是可以作为MCP Client的，因此是完全可以连接多个MCP server，其基本实现函数如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ba447-2000-4eb2-b2bb-e65f0ad3af74",
   "metadata": {
    "id": "102ba447-2000-4eb2-b2bb-e65f0ad3af74"
   },
   "outputs": [],
   "source": [
    "async def mcp_run_multi(servers_params, message):\n",
    "    # 使用 AsyncExitStack 自动管理多个上下文退出\n",
    "    async with AsyncExitStack() as stack:\n",
    "        servers = []\n",
    "        # 创建并进入所有 server 上下文\n",
    "        for p in servers_params:\n",
    "            server = MCPServerStdio(\n",
    "                name=p.get(\"name\", \"Unnamed Server\"),\n",
    "                cache_tools_list=True,\n",
    "                params={\n",
    "                    \"command\": \"uv\",\n",
    "                    \"args\": [\"run\", p[\"script\"]],\n",
    "                },\n",
    "            )\n",
    "            entered_server = await stack.enter_async_context(server)\n",
    "            servers.append(entered_server)\n",
    "\n",
    "        # 构造 agent，传入多个 server\n",
    "        agent = Agent(\n",
    "            name=\"Assistant\",\n",
    "            instructions=\"你是一名助人为乐的助手\",\n",
    "            mcp_servers=servers,\n",
    "            model_settings=ModelSettings(tool_choice=\"required\"),\n",
    "            model=deepseek_model\n",
    "        )\n",
    "\n",
    "        print(f\"Running: {message}\")\n",
    "        result = await Runner.run(starting_agent=agent, input=message)\n",
    "        print(result.final_output)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef0a96-27b6-4fb5-8576-5c94dbcb66ea",
   "metadata": {
    "id": "9aef0a96-27b6-4fb5-8576-5c94dbcb66ea"
   },
   "source": [
    "这里我们尝试创建一个“写入本地文档”的MCP服务器：`write_server.py`，代码如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd127c5-9f30-4e2b-95c2-e154d3f58350",
   "metadata": {
    "id": "9fd127c5-9f30-4e2b-95c2-e154d3f58350"
   },
   "source": [
    "```python\n",
    "import json\n",
    "import httpx\n",
    "from typing import Any\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# 初始化 MCP 服务器\n",
    "mcp = FastMCP(\"WriteServer\")\n",
    "USER_AGENT = \"write-app/1.0\"\n",
    "\n",
    "@mcp.tool()\n",
    "async def write_file(content: str) -> str:\n",
    "    \"\"\"\n",
    "    将指定内容写入本地文件。\n",
    "    :param content: 必要参数，字符串类型，用于表示需要写入文档的具体内容。\n",
    "    :return：是否成功写入\n",
    "    \"\"\"\n",
    "    return \"已成功写入本地文件。\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 以标准 I/O 方式运行 MCP 服务器\n",
    "    mcp.run(transport='stdio')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vM0ISOK8fZfp",
   "metadata": {
    "id": "vM0ISOK8fZfp"
   },
   "outputs": [],
   "source": [
    "!uv run client1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d09506-ba35-4279-8bbd-5e59a8edadae",
   "metadata": {
    "id": "62d09506-ba35-4279-8bbd-5e59a8edadae"
   },
   "source": [
    "然后尝试同时调用多个server，结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b1a26-22f4-4e50-86d9-e4203fcd08fc",
   "metadata": {
    "id": "2f9b1a26-22f4-4e50-86d9-e4203fcd08fc",
    "outputId": "f522a271-bcf2-45fc-8493-33136bbfefa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: 请帮我查询北京天气，并写入本地文档。\n",
      "北京的天气信息已查询并成功写入本地文档：\n",
      "\n",
      "🌍 Beijing, CN  \n",
      "🌡 温度: 19.94°C  \n",
      "💧 湿度: 13%  \n",
      "🌬 风速: 5.51 m/s  \n",
      "🌤 天气: 多云  \n"
     ]
    }
   ],
   "source": [
    "# 示例调用：传入多个 server 的配置\n",
    "result = await mcp_run_multi(\n",
    "    servers_params=[\n",
    "        {\"name\": \"Weather Server\", \"script\": \"weather_server.py\"},\n",
    "        {\"name\": \"Writer Server\", \"script\": \"write_server.py\"}\n",
    "    ],\n",
    "    message=\"请帮我查询北京天气，并写入本地文档。\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56544b06-7701-4d33-bfd1-31d52f5b3c49",
   "metadata": {
    "id": "56544b06-7701-4d33-bfd1-31d52f5b3c49",
    "outputId": "582be928-8c01-4198-8d43-89dcd76d344b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.new_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406c9e8-ccf6-452d-b275-49e3b22bf95d",
   "metadata": {
    "id": "1406c9e8-ccf6-452d-b275-49e3b22bf95d",
    "outputId": "49e89161-e97b-4468-90eb-3c2a574cd138"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"city\":\"Beijing\"}', call_id='call_0_a4e6781f-0fcd-46e6-ac92-b0d3b362a83f', name='query_weather', type='function_call', id='__fake_id__', status=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.new_items[0].raw_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47526cf-d138-4de1-ade4-c6846644a720",
   "metadata": {
    "id": "c47526cf-d138-4de1-ade4-c6846644a720",
    "outputId": "f443c551-e25b-4bb4-a1bb-d137ec8463d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'call_id': 'call_0_a4e6781f-0fcd-46e6-ac92-b0d3b362a83f',\n",
       " 'output': '{\"type\":\"text\",\"text\":\"🌍 Beijing, CN\\\\n🌡 温度: 19.94°C\\\\n💧 湿度: 13%\\\\n🌬 风速: 5.51 m/s\\\\n🌤 天气: 多云\\\\n\",\"annotations\":null}',\n",
       " 'type': 'function_call_output'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.new_items[1].raw_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef6907-8786-4215-a4b9-20c1ee44e14f",
   "metadata": {
    "id": "43ef6907-8786-4215-a4b9-20c1ee44e14f",
    "outputId": "1269061d-407d-4b3c-8543-b9454b9d503f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseFunctionToolCall(arguments='{\"content\":\"🌍 Beijing, CN\\\\n🌡 温度: 19.94°C\\\\n💧 湿度: 13%\\\\n🌬 风速: 5.51 m/s\\\\n🌤 天气: 多云\"}', call_id='call_0_e137b744-d34a-4dba-8758-456c2aca5eb0', name='write_file', type='function_call', id='__fake_id__', status=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.new_items[2].raw_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb73428f-8b60-4b4d-8d64-88d95a808267",
   "metadata": {
    "id": "cb73428f-8b60-4b4d-8d64-88d95a808267",
    "outputId": "a48464c4-9f82-4b0e-ac8a-9539f0e1a2d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'call_id': 'call_0_e137b744-d34a-4dba-8758-456c2aca5eb0',\n",
       " 'output': '{\"type\":\"text\",\"text\":\"已成功写入本地文件。\",\"annotations\":null}',\n",
       " 'type': 'function_call_output'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.new_items[3].raw_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036fc8c5-01d9-4270-a1d5-1a1e3243bf3f",
   "metadata": {
    "id": "036fc8c5-01d9-4270-a1d5-1a1e3243bf3f",
    "outputId": "60dcf46b-4ef8-48e0-d8bd-3c180e7b79c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseOutputMessage(id='__fake_id__', content=[ResponseOutputText(annotations=[], text='北京的天气信息已查询并成功写入本地文档：\\n\\n🌍 Beijing, CN  \\n🌡 温度: 19.94°C  \\n💧 湿度: 13%  \\n🌬 风速: 5.51 m/s  \\n🌤 天气: 多云  ', type='output_text')], role='assistant', status='completed', type='message')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.new_items[4].raw_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1800eb5-4571-42b2-b1e0-05655fc3dd6e",
   "metadata": {
    "id": "c1800eb5-4571-42b2-b1e0-05655fc3dd6e",
    "outputId": "1896f624-57be-4066-deb7-cdb543abe5e8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '请帮我查询北京天气，并写入本地文档。', 'role': 'user'},\n",
       " {'arguments': '{\"city\":\"Beijing\"}',\n",
       "  'call_id': 'call_0_a4e6781f-0fcd-46e6-ac92-b0d3b362a83f',\n",
       "  'name': 'query_weather',\n",
       "  'type': 'function_call',\n",
       "  'id': '__fake_id__'},\n",
       " {'call_id': 'call_0_a4e6781f-0fcd-46e6-ac92-b0d3b362a83f',\n",
       "  'output': '{\"type\":\"text\",\"text\":\"🌍 Beijing, CN\\\\n🌡 温度: 19.94°C\\\\n💧 湿度: 13%\\\\n🌬 风速: 5.51 m/s\\\\n🌤 天气: 多云\\\\n\",\"annotations\":null}',\n",
       "  'type': 'function_call_output'},\n",
       " {'arguments': '{\"content\":\"🌍 Beijing, CN\\\\n🌡 温度: 19.94°C\\\\n💧 湿度: 13%\\\\n🌬 风速: 5.51 m/s\\\\n🌤 天气: 多云\"}',\n",
       "  'call_id': 'call_0_e137b744-d34a-4dba-8758-456c2aca5eb0',\n",
       "  'name': 'write_file',\n",
       "  'type': 'function_call',\n",
       "  'id': '__fake_id__'},\n",
       " {'call_id': 'call_0_e137b744-d34a-4dba-8758-456c2aca5eb0',\n",
       "  'output': '{\"type\":\"text\",\"text\":\"已成功写入本地文件。\",\"annotations\":null}',\n",
       "  'type': 'function_call_output'},\n",
       " {'id': '__fake_id__',\n",
       "  'content': [{'annotations': [],\n",
       "    'text': '北京的天气信息已查询并成功写入本地文档：\\n\\n🌍 Beijing, CN  \\n🌡 温度: 19.94°C  \\n💧 湿度: 13%  \\n🌬 风速: 5.51 m/s  \\n🌤 天气: 多云  ',\n",
       "    'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_input_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5120cd-f05d-46b6-8982-1b1789c7a936",
   "metadata": {
    "id": "2a5120cd-f05d-46b6-8982-1b1789c7a936"
   },
   "source": [
    "不难看出，Agents SDK对于MCP实现过程基本遵照Function calling来执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550e225-c445-4ec2-abba-b88d13f625a2",
   "metadata": {
    "id": "b550e225-c445-4ec2-abba-b88d13f625a2",
    "outputId": "211466bc-f23c-4b65-dd07-79125e5d46be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: 请帮我查询北京和杭州天气，并写入本地文档。\n",
      "已成功查询北京和杭州的天气信息，并写入本地文档。以下是天气详情：\n",
      "\n",
      "### 北京天气\n",
      "- **温度**: 17.94°C\n",
      "- **湿度**: 16%\n",
      "- **风速**: 3.24 m/s\n",
      "- **天气**: 多云\n",
      "\n",
      "### 杭州天气\n",
      "- **温度**: 14.95°C\n",
      "- **湿度**: 40%\n",
      "- **风速**: 3.22 m/s\n",
      "- **天气**: 晴\n",
      "\n",
      "文件已保存。\n"
     ]
    }
   ],
   "source": [
    "# 示例调用：传入多个 server 的配置\n",
    "result = await mcp_run_multi(\n",
    "    servers_params=[\n",
    "        {\"name\": \"Weather Server\", \"script\": \"weather_server.py\"},\n",
    "        {\"name\": \"Writer Server\", \"script\": \"write_server.py\"}\n",
    "    ],\n",
    "    message=\"请帮我查询北京和杭州天气，并写入本地文档。\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b676e0-c9b0-4770-91ce-49876862d691",
   "metadata": {
    "id": "c0b676e0-c9b0-4770-91ce-49876862d691",
    "outputId": "7882f3e9-e637-473e-8db9-4896085d9e17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.new_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a7a25-bf1b-4d5b-a687-b71c74659817",
   "metadata": {
    "id": "637a7a25-bf1b-4d5b-a687-b71c74659817",
    "outputId": "f3642ea1-7e08-4f26-b875-06f02ef54f30",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '请帮我查询北京和杭州天气，并写入本地文档。', 'role': 'user'},\n",
       " {'arguments': '{\"city\": \"Beijing\"}',\n",
       "  'call_id': 'call_0_fe02f63b-7a08-4983-8098-6e50821100ac',\n",
       "  'name': 'query_weather',\n",
       "  'type': 'function_call',\n",
       "  'id': '__fake_id__'},\n",
       " {'arguments': '{\"city\": \"Hangzhou\"}',\n",
       "  'call_id': 'call_1_98d66c45-6268-42b5-bc0b-15a4cd857ece',\n",
       "  'name': 'query_weather',\n",
       "  'type': 'function_call',\n",
       "  'id': '__fake_id__'},\n",
       " {'call_id': 'call_0_fe02f63b-7a08-4983-8098-6e50821100ac',\n",
       "  'output': '{\"type\":\"text\",\"text\":\"🌍 Beijing, CN\\\\n🌡 温度: 17.94°C\\\\n💧 湿度: 16%\\\\n🌬 风速: 3.24 m/s\\\\n🌤 天气: 多云\\\\n\",\"annotations\":null}',\n",
       "  'type': 'function_call_output'},\n",
       " {'call_id': 'call_1_98d66c45-6268-42b5-bc0b-15a4cd857ece',\n",
       "  'output': '{\"type\":\"text\",\"text\":\"🌍 Hangzhou, CN\\\\n🌡 温度: 14.95°C\\\\n💧 湿度: 40%\\\\n🌬 风速: 3.22 m/s\\\\n🌤 天气: 晴\\\\n\",\"annotations\":null}',\n",
       "  'type': 'function_call_output'},\n",
       " {'arguments': '{\"content\":\"🌍 Beijing, CN\\\\n🌡 温度: 17.94°C\\\\n💧 湿度: 16%\\\\n🌬 风速: 3.24 m/s\\\\n🌤 天气: 多云\\\\n\\\\n🌍 Hangzhou, CN\\\\n🌡 温度: 14.95°C\\\\n💧 湿度: 40%\\\\n🌬 风速: 3.22 m/s\\\\n🌤 天气: 晴\"}',\n",
       "  'call_id': 'call_0_d9031a42-d5bb-4615-8adc-96c121b80eb3',\n",
       "  'name': 'write_file',\n",
       "  'type': 'function_call',\n",
       "  'id': '__fake_id__'},\n",
       " {'call_id': 'call_0_d9031a42-d5bb-4615-8adc-96c121b80eb3',\n",
       "  'output': '{\"type\":\"text\",\"text\":\"已成功写入本地文件。\",\"annotations\":null}',\n",
       "  'type': 'function_call_output'},\n",
       " {'id': '__fake_id__',\n",
       "  'content': [{'annotations': [],\n",
       "    'text': '已成功查询北京和杭州的天气信息，并写入本地文档。以下是天气详情：\\n\\n### 北京天气\\n- **温度**: 17.94°C\\n- **湿度**: 16%\\n- **风速**: 3.24 m/s\\n- **天气**: 多云\\n\\n### 杭州天气\\n- **温度**: 14.95°C\\n- **湿度**: 40%\\n- **风速**: 3.22 m/s\\n- **天气**: 晴\\n\\n文件已保存。',\n",
       "    'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_input_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2bfa8-eef2-4238-9b41-7f019b09f1fb",
   "metadata": {
    "id": "0be2bfa8-eef2-4238-9b41-7f019b09f1fb"
   },
   "source": [
    "整体实现流程和上一小节介绍的Agents SDK Function calling执行流程完全一致："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38047f64-eca5-42f0-9553-74402546e206",
   "metadata": {
    "id": "38047f64-eca5-42f0-9553-74402546e206"
   },
   "source": [
    "<center><img src=\"https://ml2022.oss-cn-hangzhou.aliyuncs.com/img/image-20250401162048526.png\" alt=\"image-20250401162048526\" style=\"zoom:50%;\" />"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
